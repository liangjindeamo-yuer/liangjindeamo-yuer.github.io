
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Yu Lu's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>Jin Liang</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#Educationalexperience" class="w3-bar-item w3-button">Educational Experience</a>
    <a href="#Employmentexperience" class="w3-bar-item w3-button">Employment Experience</a>
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">Yu Lu</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 80%;max-width: 320px;border-radius: 50%" alt="profile photo" src="images/1.jpg">
      <h1>Yu Lu </h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am a PHD student of the
          <a href="https://yichao0319.github.io/"> Mobile Sensing and Interaction Lab </a>, Shanghai, since 2022. 
          And I received the B.Eng major in IS from <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a> in 2022. 
          And currently, research on the Internet of Things (IoT), big data, mobile computing and security has been my ongoing pursuit.
        </p>
        <p class="w3-center">
          <a href="mailto:yulu01@sjtu.edu.cn">Email</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&user=iS-bA28AAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href="">DBLP</a> &nbsp/&nbsp
          <a href="./data/luyu.pdf">Resume</a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> May 2025, my paper Amser+ is accepted by <a href="https://ieee-iotj.org/">IEEE Internet of Things Journal</a>. </li></p>
      <p><li> May 2025, one paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7755">IEEE Transactions on Mobile Computing</a>. </li></p>
      <p><li> Mar 2025, one paper is accepted by <a href="https://www.sigmobile.org/mobisys/2025/">Mobisys 2025</a>. </li></p>
      <p><li> Feb 2025, one paper is accepted by <a href="https://chi2025.acm.org/">CHI 2025</a>. </li></p>
      <!-- <p><li> Jan 2025, 入选2024年度首届中国科协青年人才托举工程博士生专项计划.</p> -->
      <!-- <p><li> Dec 2024, my paper AMSER is accepted by <a href="https://2025.ieeeicassp.org/">ICASSP 2025</a>. </li></p>
      <p><li> Sept 2024, my paper M3CAM is accepted by <a href="https://sensys.acm.org/2024/">Sensys 2024</a>. </li></p>
      <p><li> Aug 2024, one paper is accepted by <a href="https://ipccc.org/">IPCCC 2024</a>. </li></p>
      <p><li> Aug 2024, my paper Handpad is accepted by <a href="https://uist.acm.org/2024/">UIST 2024</a>. </li></p>
      <p><li> Jul 2024, one paper is accepted by <a href="https://www.ubicomp.org/ubicomp-iswc-2024/">Ubicomp 2024</a>.</li></p> -->
      <!-- <p><li> Jul 2024, one paper is accepted by <a href="https://www.ubicomp.org/ubicomp-iswc-2024/">Ubicomp/ISWC 2024</a> as a poster paper. </li></p>
      <p><li> Jul 2024, my paper HCMG is accepted by <a href="https://mimsvai.github.io/">Ubicomp/ISWC 2024</a> as a workshop paper. </li></p> -->
      <!-- <p><li> May 2024, two papers are accepted by <a href="http://www.ic-icc.cn/2024/index.htm">ICIC 2024</a> as a poster paper and a full paper. </li></p>
      <p><li> Apr 2024, one paper is accepted by <a href="https://www.ubicomp.org/ubicomp-iswc-2024/">Ubicomp 2024</a>. </li></p>
      <p><li> Mar 2024, one paper is accepted by <a href="https://www.sigmobile.org/mobisys/2024/">Mobisys 2024</a>. </li></p>
      <p><li> Aug 2023, I am going to join MSRA for an internship under the guidance of <a href="https://scholar.google.com/citations?user=16posrQAAAAJ&hl=en&oi=ao">Prof.Qiu. </a> </li></p>
      <p><li> Feb 2023, one paper is accepted by <a href="https://ipsn.acm.org/2023/">IPSN 2023</a>. </li></p>
      <p><li> Dec 2022, my paper is accepted by <a href="https://infocom2023.ieee-infocom.org/">INFOCOM 2023</a>. </li></p> -->
  </div>

<!-- The Projects Section -->
  <div class="w3-container w3-padding-32" id="Educationalexperience">
    <h2>Educational experience</h2>
    <p class="w3-justify">
      <p><li>Bachelor's Degree: <strong>Shanghai Jiao Tong University</strong>, <strong>Information Security</strong> (Sept 2018 - Jun 2022)</li></p>
      <p><li>Ph.D. Candidate: <strong>Shanghai Jiao Tong University</strong>, <strong>Computer Science and Technology</strong> (September 2022 - Present) <br>
        Advisors: Professor <a href="https://www.cs.sjtu.edu.cn/PeopleDetail.aspx?id=77">Guangtao Xue</a>, Associate Professor <a href="https://yichao0319.github.io/">Yi-Chao Chen</a></li></p>
      
    </p>

        <!-- <h4><li>Adder Neural Networks</li></h4>
        <img style="width:96%;" src="images/AdderNet.jpg"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/AdderNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        I would like to say, <span style="color:red">AdderNet is very cool!</span> The initial idea was came up in about 2017 when climbing with some friends at Beijing. By replacing all convolutional layers (except the first and the last layers), we now can obtain comparable performance on ResNet architectures. In addition, to make the story more complete, we recent release the hardware implementation and some quantization methods. The results are quite encouraging, we can reduce both <strong>the energy consumption and thecircuit areas significantly without affecting the performance</strong>. Now, we are working on more applications to reduce the costs of launching AI algorithms such as low-level vision, detection, and NLP tasks.
        </p> 

        <h4><li>GhostNet on MindSpore: SOTA Lightweight CV Networks</li></h4>
        <img style="width:96%;" src="images/GhostNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://live.huawei.com/huaweiconnect/meeting/cn/5872.html">Huawei Connect (HC) 2020</a> | <a style="color: #447ec9" href="https://www.mindspore.cn/resources/hub">MindSpore Hub</a>
        </p>
        <p class="w3-justify">
        The initial verison of GhostNet was accepted by CVPR 2020, which achieved SOTA performance on ImageNet: <span style="color:red">75.7%</span> top1 acc with only <span style="color:red">226M FLOPS</span>. In the current version, we release a series computer vision models (e.g. int8 quantization, detection, and larger networks) on <strong>MindsSpore 1.0</strong> and <strong>Mate 30 Pro (Kirin 990)</strong>.
        </p> 

        <h4><li>AI on Ascend: Real-Time Video Style Transfer</li></h4>
        <img style="width:32%;" src="images/atlas200.png"> &nbsp&nbsp <img style="width:60%;" src="images/video.gif">
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://www.huaweicloud.com/intl/en-us/HDC.Cloud.html">Huawei Developer Conference (HDC) 2020</a> | <a style="color: #447ec9" href="https://developer.huaweicloud.com/exhibition/Atlas_neural_style.html">Online Demo</a>
        </p>
        <p class="w3-justify">
        This project aims to develop a video style transfer system on the <strong>Huawei Atlas 200 DK AI developer Kit</strong>. The latency of the original model for processing one image is about <span style="color:red">630ms</span>. After accelerating it using our method, the lantency now is about <span style="color:red">40ms</span>. 
        </p>   -->

  </div>
  
  <!-- The Talks Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="Employmentexperience">
    <h2>Employment experience</h2>

    <p><li>From Aug 2023 to Mar 2024,  an intern with Shanghai Wireless Group Group at  <strong>Microsoft Research Asia</strong> under the guidance of <a href="https://scholar.google.com/citations?user=16posrQAAAAJ&hl=en&oi=ao">Prof.Qiu </a>.</li></p>
      <!-- <p><li> 10/2021, Vision Transformer at <a href="http://valser.org/2021/#/tutorial">VALSE 2021, Hangzhou, China</a>.</li></p>
	  <p><li> 05/2021, Adder Neural Network at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>. Thanks <a href="https://datawisdom.ca/">Vahid</a> for the invitation.</li></p>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/"><strong>VALSE</strong></a> Webinar.</li></p>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/">Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/"> <strong>QbitAI</strong></a> using <a  href="https://www.bilibili.com/"><strong>bilibili</strong></a>.</li></p> -->
  </div>
 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32" id="publications">
    <h2>Research</h2>
      <p class="w3-left-align" style="line-height:200%">
        I'm interested in devleoping <strong>efficient models</strong> for mobile computing. (* denotes equal contribution, <sup>&</sup> denotes corresponding author)
      </p>
    
    <h4> Poster/Demo/Workshop Papers:</h4>
    <ol>
      <p>
        <li><strong>Toward High Spatial Resolution and Low Ambiguity in Wideband Signal Receiver Beamforming for VR/AR</strong>
        <br>
        Longyuan Ge, Juntao Zhou, Dian Ding, Yi-Chao Chen, <strong>Yu Lu</strong>, Yida Wang, Guangtao Xue
        <br>
        <em>Ubicomp Workshop MIMSVAI</em> 2025  | <a style="color: #447ec9" href="">paper</a>  
      </p>


      <p>
        <li><strong>Effective Local Texture Estimation Using Wavelet Transforms for Arbitrary-Scale Super-Resolution</strong>
        <br>
        Baihong Qian*, <strong>Yu Lu*</strong>, Dian Ding<sup>&</sup>, Yi-Chao Chen, Qiaoling Xiao, Guanghui Gao, Zhengguang Xiao, Guangtao Xue<sup>&</sup>
        <br>
        <em>ICIC Poster</em> 2025  | <a style="color: #447ec9" href="">paper</a>  
      </p>

      <p>
        <li><strong>HCMG: Human-Capacitance based Micro Gesture for VR/AR</strong>
        <br>
        <strong>Yu Lu</strong>, Dian Ding<sup>&</sup>, Ran Wang, Guangtao Xue
        <br>
        <em>Ubicomp Workshop MIMSVAI</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        <br>
        <span style='color: red;'> Best Paper Award</span>
      </p>

      <p>
        <li><strong>Enable Touch-based Communication between Laptop and Smartwatch</strong>
        <br>
        Dian Ding, Yijie Li, Hao Pan, <strong>Yu Lu</strong>, Yi-Chao Chen, Guangtao Xue<sup>&</sup>
        <br>
        <em>Ubicomp Poster</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
      </p>

      <p>
        <li><strong>VCEMO: Multi-Modal Emotion Recognition for Chinese Voiceprints</strong>
        <br>
        Jinghua Tang*, Liyun Zhang*, <strong>Yu Lu</strong>, Dian Ding<sup>&</sup>, Lanqing Yang, YiChao Chen, Minjie Bian, Xiaoshan Li<sup>&</sup>, Guangtao Xue
        <br>
        <em>ICIC Poster</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
      </p>
    </ol>
      

      

    
    <h4> Conference Papers:</h4>

    <ol>
      <p>
        <li><strong>High-resolution mmWave Imaging using Metasurface and Diffusion</strong>
        <br>
        Yida Wang, <strong>Yu Lu</strong>, Yuxuan Zhou, Yifei Shen, Lili Qiu, Zeyuan Lai, Yi-Chao Chen<sup>&</sup>, Hao Pan, Juntao Zhou, Dian Ding, Mei Wang, Guangtao Xue, Qian Zhang
        <br>
        <em>Mobisys (CCF B)</em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        <br>
        <span style='color: red;'> Best Artifact Runner Up</span>
      </p>

      <p>
        <li><strong> M^2Silent: Enabling Multi-user Silent Speech Interactions via Multi-directional Speakers in Shared Spaces</strong>
        <br>
        Juntao Zhou, Dian Ding<sup>&</sup>, Yijie Li, <strong>Yu Lu</strong>, Yida Wang, Yongzhao Zhang, Yi-Chao Chen<sup>&</sup>, Guangtao Xue
        <br>
        <em>CHI (CCF A)</em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        <br>
      </p>

      <p>
        <li><strong> AMSER: Accelerate Mobile Speech Emotion Recognition with Signal Compression</strong>
        <br>
        <strong>Yu Lu*</strong>, Ran Wang*, Dian Ding<sup>&</sup>,  Han Zhang, Liyun Zhang, Lanqing Yang, Yi-Chao Chen, Guangtao Xue<sup>&</sup>
        <br>
        <em>ICASSP (CCF B)</em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        <br>
      </p>

      <p>
        <li><strong> DASIV: Directional Acoustic Sensing based Intelligent Vehicle Interaction System</strong>
        <br>
        Dinghua Zhao*, Juntao Zhou*, Dian Ding<sup>&</sup>, <strong>Yu Lu</strong>, Yijie Li, Hang Yang, Yi-Chao Chen, Guangtao Xue
        <br>
        <em>IPCCC (CCF C)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        <br>
      </p>
      <p>
        <li><strong>M^3Cam: Extreme Super-resolution via Multi-Modal Optical Flow for Mobile Cameras</strong>
        <br>
        <strong>Yu Lu*</strong>, Dian Ding*, Hao Pan<sup>&</sup>, Yongjian Fu, Liyun Zhang, Feitong Tan, Ran Wang, Yi-Chao Chen, Guangtao Xue, Ju Ren
        <br>
        <em>Sensys (CCF B)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        <br>
      </p>
      <p>
        <li><strong>HandPad: Make Your Hand an On-the-go Writing Pad via Human Capacitance</strong>
        <br>
        <strong>Yu Lu</strong>, Dian Ding<sup>&</sup>, Hao Pan,Yijie Li,Juntao Zhou,Yongjian Fu, Yongzhao Zhang, Yi-Chao Chen, Guangtao Xue
        <br>
        <em>UIST (CCF A)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        <br>
        <!-- <span style='color: red;'> The First Accepted Paper at UIST by Department of Computer Science and Engineering, SJTU</span> -->
      </p>
      
      <p>
        <li><strong>CarbonNet: Enterprise-Level Carbon Emission Prediction with Large-Scale Datasets</strong>
        <br>
        Jinghua Tang, Nan Fang, Lanqing Yang<sup>&</sup>, Yuqiao Pei, Ran Wang, Dian Ding, <strong>Yu Lu</strong>, Guangtao Xue
        <br>
        <em>ICIC (CCF C)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
      </p>


      <p>
        <li><strong>Adaptive Metasurface-Based Acoustic Imaging using Joint Optimization</strong>
        <br>
        Yongjian Fu, Yongzhao Zhang, <strong>Yu Lu</strong>, Lili Qiu, Yi-Chao Chen, Yezhou Wang, Mei Wang, Yijie Li, Ju Ren<sup>&</sup>, Yaoxue Zhang
        <br>
        <em>Mobisys (CCF B)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
      </p>


      <p>
      <li><strong>Addressing Practical Challenges in Acoustic Sensing To Enable Fast Motion Tracking</strong>
      <br>
      Yongzhao Zhang, Hao Pan, Yi-Chao Chen, Lili Qiu, <strong>Yu Lu</strong>, Guangtao Xue, Jiadi Yu, Feng Lyu, and Haonan Wang
      <br>
      <em>IPSN (CCF B)</em> 2023  | <a style="color: #447ec9" href="">paper</a> 
      </p>

      <p>
      <li><strong>Effectively Learning Moire QR Code Decryption from Simulated Data</strong>
      <br>
      <strong>Yu Lu</strong>, Hao Pan<sup>&</sup>, Feitong Tan, Yi-Chao Chen,Jiadi Yu, Jinghai He, Guangtao Xue<sup>&</sup> 
      <br>
      <em>INFOCOM (CCF A)</em> 2023 | <a style="color: #447ec9" href="./data/Infocom2023_CR_ver2.pdf">paper</a>
      </p>

      </ol>

      <h4> Journal Papers:</h4>
      
      
      <ol>
        <p>
          <li><strong>Moir´eComm: Secure Screen-camera Communication based on Moir´e Cryptography</strong>
          <br>
          Hao Pan,  Yongjian Fu<sup>&</sup>,  <strong>Yu Lu</strong>,  Feitong Tan,  Yi-Chao Chen,  and Ju Ren
          <br>
          <em>TDSC (CCF A) </em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        </p>


        <p>
          <li><strong>Amser+: Accelerating Mobile Speech Emotion Recognition in IoT Environments with Mel Feature Compression</strong>
          <br>
          <strong>Yu Lu</strong>,Ran Wang, Dian Ding<sup>&</sup>, Yijie Li, Yongzhao Zhang, Lanqing Yang, Yi-Chao Chen, Guangtao Xue<sup>&</sup>
          <br>
          <em>IoT-J (CCF C & JCR Q1) </em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        </p>

        <p>
          <li><strong>TouchHBC: Touch-based Human Body Communication via Leakage Current</strong>
          <br>
          Dian Ding, Yijie Li, Hao Pan,<strong>Yu Lu</strong>, Yongzhao Zhang, Yi-Chao Chen, Guangtao Xue<sup>&</sup>
          <br>
          <em>IEEE TMC (CCF A)</em> 2025  | <a style="color: #447ec9" href="">paper</a> 
        </p>

        <p>
          <li><strong>Visar: Projecting Virtual Sound Spots for Acoustic Augmented Reality Using Air Nonlinearity</strong>
          <br>
          Juntao Zhou, Yijie Li<sup>&</sup>, Yida Wang, Dian Ding,  <strong>Yu Lu</strong>, Yi-Chao Chen<sup>&</sup>, and Guangtao Xue
          <br>
          <em>IMWUT (CCF A)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        </p>

        <p>
          <li><strong>Pushing the Limits of Acoustic Spatial Perception via Incident Angle Encoding</strong>
          <br>
          Yongjian Fu, Yongzhao Zhang, Hao Pan, <strong>Yu Lu</strong>, Xinyi Li, Lili Chen, Ju Ren<sup>&</sup>, Xiong Li, Xiaosong Zhang, Yaoxue Zhang
          <br>
          <em>IMWUT (CCF A)</em> 2024  | <a style="color: #447ec9" href="">paper</a> 
        </p>

        
      <!-- <p>
      <li><strong>GhostNets on Heterogeneous Devices via Cheap Operations</strong>
      <br>
      Kai Han, <strong>Yunhe Wang</strong>, Chang Xu, Jianyuan Guo, Chunjing Xu, Enhua Wu, Qi Tian 
      <br>
      <em>IJCV</em> 2022 | <a style="color: #447ec9" href="https://link.springer.com/content/pdf/10.1007/s11263-022-01575-y.pdf">paper</a> | <a style="color: #447ec9" href="https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet_d">MindSpore code</a> | <a style="color: #447ec9" href="https://github.com/huawei-noah/Efficient-AI-Backbones">Pytorch code</a>
      </p> -->


      </ol>

    </p>
  </div>

 <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>

    <p><li>Reviewer of <a href="https://2025.ieeeicme.org/">IEEE ICME 2025</a>.</p> 
    <p><li>Reviewer of <a href="https://ieeebibm.org/BIBM2024/">BIBM 2024</a>.</p>
    <p><li>Reviewer of <a href="http://www.ic-icc.cn/2024/index.htm">ICIC 2024</a>.</p>
    <p><li>Reviewer of <a href="https://icdcs2024.icdcs.org/">IEEE ICDCS 2024</a>.</p> 
      <!-- <p><li> Area Chair of <a href="https://icml.cc/Conferences/2023">ICML 2021</a>, <a href="https://nips.cc/Conferences/2022/">NeurIPS 2022</a>, <a href="https://icml.cc/Conferences/2021">ICML 2021</a>, <a href="https://nips.cc/Conferences/2021/">NeurIPS 2021</a>.</p>
      <p><li> Action Editor of <a href="https://jmlr.org/tmlr/">TMLR</a> (Transactions on Machine Learning Research).</p>
      <p><li> Senior Program Committee Members of <a href="https://ijcai-21.org/">IJCAI 2021</a>, <a href="https://www.ijcai20.org/">IJCAI 2020</a> and <a href="https://www.ijcai19.org/program-committee.html">IJCAI 2019</a>.</p>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE T-PAMI</a>, <a href="https://www.springer.com/journal/11263">IJCV</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE T-IP</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE T-MM</a>, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69">IEEE T-KDE</a>, etc.</p>
      <p><li> Program Committee Members of ICCV 2021, AAAI 2021, ICLR 2021, NeurIPS 2020, ICML 2020, ECCV 2020, CVPR 2020, ICLR 2020, AAAI 2020, ICCV 2019, CVPR 2019, ICLR 2019, AAAI 2019, IJCAI 2018, AAAI 2018, NeurIPS 2018, etc.</p> -->
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> Jun 2025, MIMSID won the Best Artifact Runner Up at the <a href="https://www.sigmobile.org/mobisys/2025/">Mobisys 2025</a>. </p>
    <p><li> Jan 2025, 入选2024年度首届中国科协青年人才托举工程博士生专项计划</p>
    <p><li> Dec 2024, National Scholarship of China, The Ministry of Education of China</p>
    <p><li> Oct 2024, HCMG won the best paper award at the <a href="https://mimsvai.github.io/">Ubicomp MIMSVAI 2024</a>.</p>
    <p><li> Jun 2022, Outstanding Graduate of Shanghai Jiao Tong University</p>

  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">

    <!-- Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a></br> -->

  <!-- Default Statcounter code for Yunhe Wang's Homepage
  https://www.wangyunhe.site -->
  <!-- No. -->
  <!-- <script type="text/javascript">
  var sc_project=12347113; 
  var sc_invisible=0; 
  var sc_security="21aca5d1"; 
  var sc_https=1; 
  var scJsHost = "https://";
  document.write("<sc"+"ript type='text/javascript' src='" + scJsHost+
  "statcounter.com/counter/counter.js'></"+"script>");
  </script>  -->
  <!-- Visitor Since Feb 2022. Powered by <a href="https://www.w3schools.com/w3css/default.asp" title="W3.CSS" target="_blank" class="w3-hover-opacity">w3.css</a> -->
  <noscript>
    <div class="statcounter"><a title="Web Analytics Made Easy -
  StatCounter" href="https://statcounter.com/" target="_blank"><img
  class="statcounter" src="https://c.statcounter.com/12347113/0/21aca5d1/0/"
  alt="Web Analytics Made Easy - StatCounter"></a></div>
  </noscript>
  <!-- End of Statcounter Code -->

  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
